{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96e9664-0e8c-45f6-87aa-a0398059608e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a96e9664-0e8c-45f6-87aa-a0398059608e",
    "outputId": "04f6ded3-6965-476e-c44a-520512a41a1c"
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "import time\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import numpy as np\n",
    "import pickle\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "import re\n",
    "import string\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B9WOY3g-OBVH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B9WOY3g-OBVH",
    "outputId": "9f49fa6d-0160-4e65-8d2b-33b550bf538a"
   },
   "outputs": [],
   "source": [
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92447b-c039-4348-8d5e-34bec78f70b8",
   "metadata": {
    "id": "5b92447b-c039-4348-8d5e-34bec78f70b8"
   },
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc90a9f-027f-45f6-9b97-4a9b72716eec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cc90a9f-027f-45f6-9b97-4a9b72716eec",
    "outputId": "44365c38-00f2-4314-d659-14ab88056269"
   },
   "outputs": [],
   "source": [
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76990142-0a24-4830-99fe-e69174a3a3aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76990142-0a24-4830-99fe-e69174a3a3aa",
    "outputId": "efa87f1c-c47e-4bd1-ca52-bac62d525592"
   },
   "outputs": [],
   "source": [
    "from gensim import corpora,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RapNcjtrOZp9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RapNcjtrOZp9",
    "outputId": "16b9964a-87a1-4d49-e202-feb271ddfa42"
   },
   "outputs": [],
   "source": [
    "!pip install -U mittens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PvWQ6MYjrY1D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvWQ6MYjrY1D",
    "outputId": "f006750c-14b0-4c36-fed9-620b0cc129ef"
   },
   "outputs": [],
   "source": [
    "from mittens import GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hR2yuBEdOrk1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hR2yuBEdOrk1",
    "outputId": "9322365f-644d-4ba0-84b1-0ad4761c0e29"
   },
   "outputs": [],
   "source": [
    "# from glove import Glove\n",
    "# from glove import Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8c965-7a69-4018-8805-3e60ab72a064",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52e8c965-7a69-4018-8805-3e60ab72a064",
    "outputId": "c6acf4a9-f7f8-4545-a828-17acb22e1f33"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec,FastText\n",
    "from gensim.test.utils import get_tmpfile\n",
    "# from glove import Glove, Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6cd07-d128-4f16-8296-f249834ebd27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f9a6cd07-d128-4f16-8296-f249834ebd27",
    "outputId": "a673e775-b61c-4b1a-930a-a2662700737f"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import nltk\n",
    "import gensim\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import numpy as np\n",
    "from gensim import corpora,models\n",
    "import time\n",
    "import pickle\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "from gensim.models import Word2Vec,FastText\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import distance\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jbLFNp4oOyNO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jbLFNp4oOyNO",
    "outputId": "c268bf8b-e2ee-47c2-c2b3-6b49b9e2b552"
   },
   "outputs": [],
   "source": [
    "#mounting the google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d2314e-64b5-4159-8ba2-2b84640ec579",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 875
    },
    "id": "e6d2314e-64b5-4159-8ba2-2b84640ec579",
    "outputId": "823964ce-2c6e-4bb7-f1d0-f4a50a582797"
   },
   "outputs": [],
   "source": [
    "#reading the pre-downloaded csv file from Bugzilla\n",
    "data=pd.read_csv('preproccessed_whole_dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef908f-9782-4035-9ffc-11d6534201cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "c8ef908f-9782-4035-9ffc-11d6534201cc",
    "outputId": "530cef0f-b979-4332-f406-fcf85226fa3b"
   },
   "outputs": [],
   "source": [
    "data = data.drop(columns = [\"Unnamed: 0\"])\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f0c44-f878-4ad7-809b-9e1bcc4fb6d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "0f9f0c44-f878-4ad7-809b-9e1bcc4fb6d7",
    "outputId": "131bf523-8071-42b7-cd60-b73201838e3d"
   },
   "outputs": [],
   "source": [
    "data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b050a6-0b92-4a1d-a7b8-b751fabecbd0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "d7b050a6-0b92-4a1d-a7b8-b751fabecbd0",
    "outputId": "b60f07e2-f2ba-43d3-ad74-249fc31fd182"
   },
   "outputs": [],
   "source": [
    "data =  data.rename(columns={\"Bug_Id\": \"Bug ID\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ff56fa-f3a0-41a2-9c04-c28e2f30d6c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "30ff56fa-f3a0-41a2-9c04-c28e2f30d6c8",
    "outputId": "3ca0350c-a843-424d-dd3a-844ceeae5117"
   },
   "outputs": [],
   "source": [
    "#Dropping duplicate entities\n",
    "data = data.drop_duplicates()\n",
    "data = data.dropna(axis=0, subset=['Bug ID'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc532084-9709-4ad9-8cd9-6440b10dd10a",
   "metadata": {
    "id": "cc532084-9709-4ad9-8cd9-6440b10dd10a",
    "tags": []
   },
   "source": [
    "## On complete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497bfc9-7d7a-436f-b06f-3559f0bede08",
   "metadata": {
    "id": "f497bfc9-7d7a-436f-b06f-3559f0bede08"
   },
   "outputs": [],
   "source": [
    "data[\"Description\"]= data[\"Description\"].str.replace(\"fixed in HEAD\", \"\", case = False)\n",
    "data[\"Description\"]= data[\"Description\"].str.replace(\"has been marked as readonly\", \" \", case = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd273b7-d823-4798-a4b7-19d90d9dd347",
   "metadata": {
    "id": "efd273b7-d823-4798-a4b7-19d90d9dd347"
   },
   "outputs": [],
   "source": [
    "#Text Cleaning round 1 (removing punctutions)\n",
    "\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "#     print(text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = re.sub('\\w*\\f\\w*', '', text)\n",
    "    text = re.sub('\\(.*?\\)', '', text)\n",
    "    text = re.sub('\\[.*]\\)', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da94b3d0-3a2b-42fa-a328-f6f6f7d1151f",
   "metadata": {
    "id": "da94b3d0-3a2b-42fa-a328-f6f6f7d1151f"
   },
   "outputs": [],
   "source": [
    "# data = data.drop(columns=['Unnamed: 0'])\n",
    "data = data.dropna(axis=0, subset=['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a92c35d-af5c-4117-baec-5c0b6c060b4c",
   "metadata": {
    "id": "0a92c35d-af5c-4117-baec-5c0b6c060b4c"
   },
   "outputs": [],
   "source": [
    "data['Description'] = data['Description'].apply(clean_text_round1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a67bf1-607e-45e6-9f43-782830df81bb",
   "metadata": {
    "id": "d3a67bf1-607e-45e6-9f43-782830df81bb"
   },
   "outputs": [],
   "source": [
    "# Apply a second round of cleaning (removing punctuations)\n",
    "def clean_text_round2(text):\n",
    "    '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "    text = re.sub('[‘’“”…]', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\t', '', text)\n",
    "    return text\n",
    "\n",
    "round2 = lambda x: clean_text_round2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e692db3b-5bfa-4f0d-8d87-6599da078546",
   "metadata": {
    "id": "e692db3b-5bfa-4f0d-8d87-6599da078546"
   },
   "outputs": [],
   "source": [
    "data['Description'] = data['Description'].apply(clean_text_round2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OIovvV5BPPk3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIovvV5BPPk3",
    "outputId": "c7259ed3-806f-4b8e-e284-28b640a762ef"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c11bbd-abe9-4dd4-9c7c-27c845d58d03",
   "metadata": {
    "id": "b3c11bbd-abe9-4dd4-9c7c-27c845d58d03"
   },
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "def lemmatize(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 5:\n",
    "            result.append(lemmatize(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99265d49-d86f-4037-b990-268d0d0ca565",
   "metadata": {
    "id": "99265d49-d86f-4037-b990-268d0d0ca565"
   },
   "outputs": [],
   "source": [
    "data['Description'] = data['Description'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29113240-7fc0-4e30-a917-e13cbc131e26",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29113240-7fc0-4e30-a917-e13cbc131e26",
    "outputId": "e2d7fd59-6892-4f96-e4c7-379dcb2ffd06"
   },
   "outputs": [],
   "source": [
    "data['Duplicate_Bug_Ids'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19634f56-d220-420e-8530-3f452268a6f8",
   "metadata": {
    "id": "19634f56-d220-420e-8530-3f452268a6f8"
   },
   "outputs": [],
   "source": [
    "#Saving all the duplicate reports into a csv file as a testing set\n",
    "duplicate_reports = data.dropna(axis=0, subset=['Duplicate_Bug_Ids'])\n",
    "duplicate_reports.reset_index(drop=True)\n",
    "duplicate_reports.to_csv('duplicate_reports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec311f8-499d-4abe-b3d2-b46c82ff3d51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 840
    },
    "id": "5ec311f8-499d-4abe-b3d2-b46c82ff3d51",
    "outputId": "4157e39a-cafa-4cc4-c899-ba48e6363a8b"
   },
   "outputs": [],
   "source": [
    "#Seperating all the master reports into a dataframe\n",
    "master_reports = data[data.isnull().any(axis=1)]\n",
    "master_reports.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af0fdd-fb36-426a-a426-84fba0416dbc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a3af0fdd-fb36-426a-a426-84fba0416dbc",
    "outputId": "990a3e87-3b06-459f-a859-9c3f6ca45956"
   },
   "outputs": [],
   "source": [
    "master_reports.Description.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcffc8b5-dd93-4c46-ac1a-58ad79c5f79f",
   "metadata": {
    "id": "dcffc8b5-dd93-4c46-ac1a-58ad79c5f79f"
   },
   "outputs": [],
   "source": [
    "mr = pd.DataFrame()\n",
    "count = 0\n",
    "\n",
    "for i in range(len(master_reports)):\n",
    "    if len(master_reports.Description.iloc[i]) > 2:\n",
    "        mr = pd.concat([mr, master_reports.iloc[[i]]], ignore_index=True)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262a7c0-9248-4864-8b03-8c8baf2a26d9",
   "metadata": {
    "id": "e262a7c0-9248-4864-8b03-8c8baf2a26d9"
   },
   "outputs": [],
   "source": [
    "master_reports.to_csv('master_reports.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580b85e7-2a38-4aca-91c4-1cf72814c001",
   "metadata": {
    "id": "580b85e7-2a38-4aca-91c4-1cf72814c001"
   },
   "outputs": [],
   "source": [
    "#importing the CSV file of the master reports from google drive into a dataframe\n",
    "master_reports = pd.read_csv('master_reports.csv')\n",
    "master_reports = master_reports.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed42ff-2b70-40e1-b429-d7c61b45636e",
   "metadata": {
    "id": "f3ed42ff-2b70-40e1-b429-d7c61b45636e"
   },
   "outputs": [],
   "source": [
    "master_reports['Description'] = master_reports['Description'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ee08ab-9e44-428b-a512-b1ff00e77193",
   "metadata": {
    "id": "b6ee08ab-9e44-428b-a512-b1ff00e77193"
   },
   "outputs": [],
   "source": [
    "#Creating a dictionary using gensim library\n",
    "dictionary = gensim.corpora.Dictionary(master_reports['Description'])\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece2935-a62e-48b3-bc3e-0485afaae158",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bece2935-a62e-48b3-bc3e-0485afaae158",
    "outputId": "46d9d451-1397-4418-a90a-84a3853be383"
   },
   "outputs": [],
   "source": [
    "#Print top 20 words from the dictionary\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab00ef-a94d-4050-85cb-b104008ae63c",
   "metadata": {
    "id": "11ab00ef-a94d-4050-85cb-b104008ae63c"
   },
   "outputs": [],
   "source": [
    "#Creating BoW using the the dictionary\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in master_reports['Description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb6a5d-b12a-4550-9641-567c057fd565",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ccb6a5d-b12a-4550-9641-567c057fd565",
    "outputId": "bfb56355-e886-4312-a29e-1dc7021dac00"
   },
   "outputs": [],
   "source": [
    "#Printing the BoW for single document\n",
    "bow_doc_8 = bow_corpus[8]\n",
    "for i in range(len(bow_doc_8)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_8[i][0],\n",
    "                                               dictionary[bow_doc_8[i][0]],\n",
    "bow_doc_8[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c041eaa-b709-44b6-94dd-489df9288d67",
   "metadata": {
    "id": "7c041eaa-b709-44b6-94dd-489df9288d67"
   },
   "outputs": [],
   "source": [
    "# open a file, where you stored the pickled data\n",
    "f= open('bow_corpus.pickle', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(bow_corpus, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8b891-42c1-42c0-93e5-341d8868ef82",
   "metadata": {
    "id": "f5f8b891-42c1-42c0-93e5-341d8868ef82"
   },
   "outputs": [],
   "source": [
    "#open a file, where you stored the pickled data\n",
    "file = open('dictionary.pickle', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(dictionary, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e793d8c-91b7-4677-9cb2-4b4b2235ae51",
   "metadata": {
    "id": "2e793d8c-91b7-4677-9cb2-4b4b2235ae51"
   },
   "outputs": [],
   "source": [
    "#Preparing the parameters for LDA model\n",
    "corpus = bow_corpus\n",
    "no_of_topics = 10\n",
    "dictionary = dictionary\n",
    "p = 20\n",
    "k = 2\n",
    "epochs = 100\n",
    "\n",
    "#Training the LDA model on the BoW corpus\n",
    "lda_model = gensim.models.LdaMulticore(corpus, num_topics=no_of_topics, id2word=dictionary, passes=p, workers=k, iterations=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391b9ad5-9943-41ab-968f-baec645c78f6",
   "metadata": {
    "id": "391b9ad5-9943-41ab-968f-baec645c78f6"
   },
   "outputs": [],
   "source": [
    "# save model to disk (no need to use pickle module)\n",
    "lda_model.save('lda_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaec54e2-5ff1-4716-b52b-d154d5c37316",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aaec54e2-5ff1-4716-b52b-d154d5c37316",
    "outputId": "9b108827-91e4-4e7c-db8b-dd39ffcd6720"
   },
   "outputs": [],
   "source": [
    "# Printing the topics and the propability distributions of words in those topics\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d9f45b-060d-4329-808c-2ba773f36cd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34d9f45b-060d-4329-808c-2ba773f36cd8",
    "outputId": "81770ca1-eca7-469c-af5f-a7a1b66617be"
   },
   "outputs": [],
   "source": [
    "#Let's evaluate the model using Perplexity and Coherence Bag of words- Title\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(bow_corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data['Description'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1b52d-8045-4336-aefe-ca7989deee44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 861
    },
    "id": "36e1b52d-8045-4336-aefe-ca7989deee44",
    "outputId": "d736af1f-ec74-4aa1-b581-be8fbc128b9f"
   },
   "outputs": [],
   "source": [
    "# for visualization of LDA\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, bow_corpus, dictionary)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GV9KTv6z2jxt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "GV9KTv6z2jxt",
    "outputId": "04094b24-6107-48e2-c391-4b792720d392"
   },
   "outputs": [],
   "source": [
    "type(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9e5656-919d-4b2d-b723-c0d82725bce5",
   "metadata": {
    "id": "ff9e5656-919d-4b2d-b723-c0d82725bce5"
   },
   "outputs": [],
   "source": [
    "for c in range(10):\n",
    "    exec(f'topic_{c} = pd.DataFrame()')\n",
    "    for i in range(len(master_reports)):\n",
    "        topic = lda_model[dictionary.doc2bow(master_reports.Description[i])]\n",
    "        topic = np.asarray(topic)\n",
    "        if int(topic[np.argmax(topic[:,1]), 0]) == c:\n",
    "            exec(f'topic_{c} = pd.concat([topic_{c}, master_reports.loc[[i]]])')\n",
    "            exec(f'topic_{c} = topic_{c}.reset_index(drop=True)')\n",
    "            exec(f'topic_{c}.to_csv(\"topic_{c}.csv\")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9139edc7-6d1b-4f6f-bf73-826f64a412f1",
   "metadata": {
    "id": "9139edc7-6d1b-4f6f-bf73-826f64a412f1"
   },
   "outputs": [],
   "source": [
    "# open a file, where you stored the pickled data\n",
    "# f = open('/content/drive/MyDrive/BugEnricher/bow_corpus.pickle', 'rb')\n",
    "# bow_corpus=pickle.load(f)\n",
    "\n",
    "# file = open('/content/drive/MyDrive/BugEnricher/bow_corpus.pickle', 'rb')\n",
    "# dictionary=pickle.load(file)\n",
    "\n",
    "# later on, load trained model from file\n",
    "# lda_model =  models.LdaModel.load('/content/drive/MyDrive/BugEnricher/LDA/lda_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26762b-5be1-4eb7-b0df-cd04e14c526e",
   "metadata": {
    "id": "0f26762b-5be1-4eb7-b0df-cd04e14c526e"
   },
   "outputs": [],
   "source": [
    "#Import all the clusters from the drive\n",
    "for c in range(10):\n",
    "    exec('topic_{} = pd.read_csv(\"topic_{}.csv\")'.format(c,c))\n",
    "    # exec(\"topic_{}= topic_{}.drop(columns=['Unnamed: 0'])\".format(c,c))\n",
    "    exec(\"topic_{}['Description'] = topic_{}['Description'].map(preprocess)\".format(c,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7988e-3f96-4a06-b732-aa6b9a4f8b3a",
   "metadata": {
    "id": "5fb7988e-3f96-4a06-b732-aa6b9a4f8b3a"
   },
   "outputs": [],
   "source": [
    "#creating a corpus for Word2Vec and FastText models\n",
    "for i in range(10):\n",
    "    exec('sent_{} = []'.format(i))\n",
    "    exec('x= topic_{}'.format(i))\n",
    "    for j in range(len(x)):\n",
    "        exec('sent_{}.append(topic_{}.Description[{}])'.format(i,i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d3617-5643-4bec-9fe7-14e3f2b8dd4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "537d3617-5643-4bec-9fe7-14e3f2b8dd4e",
    "outputId": "b134f66e-2d73-46eb-b022-2678f97d4029"
   },
   "outputs": [],
   "source": [
    "for sent in range(10):\n",
    "    exec('print(len(sent_{}))'.format(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wclaIEZqxAm0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wclaIEZqxAm0",
    "outputId": "6f67f74e-9ed3-41d2-aba0-23b879c2aa0e"
   },
   "outputs": [],
   "source": [
    "!pip install glove-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NaE5cP4_zHDE",
   "metadata": {
    "id": "NaE5cP4_zHDE"
   },
   "outputs": [],
   "source": [
    "from glove import Glove, Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e74fc4-6fcf-4dc3-9a69-463918248ba2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81e74fc4-6fcf-4dc3-9a69-463918248ba2",
    "outputId": "fe3fe2a1-4411-41b0-80b9-e14ee799f7e5",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Training GloVe model for each cluster\n",
    "for cluster in range(10):\n",
    "    vector_size = 100\n",
    "    exec('glove_corpus{}=Corpus()'.format(cluster, cluster))\n",
    "    exec('glove_corpus{}.fit(sent_{})'.format(cluster, cluster))\n",
    "    exec('glove{}= Glove(no_components=vector_size, learning_rate=0.18, alpha=0.75, max_count=100, max_loss=10.0, random_state=None)'.format(cluster, cluster))\n",
    "    exec('glove{}.fit(glove_corpus{}.matrix, epochs=100, no_threads=3, verbose=True)'.format(cluster, cluster))\n",
    "    exec('transformer = lambda dictionary2:glove{}.transform_paragraph(words, epochs=100,ignore_missing=False)'.format(cluster, cluster))\n",
    "    exec('glove{}.add_dictionary(glove_corpus{}.dictionary)'.format(cluster, cluster))\n",
    "\n",
    "    #Save the all the models in individual file\n",
    "    exec('path = get_tmpfile(\"glove{}.model\")'.format(cluster))\n",
    "    exec('glove{}.save(\"glove{}.model\")'.format(cluster, cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0843897-fe5c-4f7a-8c13-9b706cda5a66",
   "metadata": {
    "id": "f0843897-fe5c-4f7a-8c13-9b706cda5a66"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43805287-6a89-4dba-8aaf-d20038d41e73",
   "metadata": {
    "id": "43805287-6a89-4dba-8aaf-d20038d41e73"
   },
   "outputs": [],
   "source": [
    "# importing all the clusters created using LDA based topic modeling\n",
    "for c in range(10):\n",
    "    exec('topic_{} = pd.read_csv(\"topic_{}.csv\")'.format(c,c))\n",
    "    # exec(\"topic_{}= topic_{}.drop(columns=['Unnamed: 0'])\".format(c,c))\n",
    "    exec(\"topic_{}['Description'] = topic_{}['Description'].map(preprocess)\".format(c,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5723851-9ada-4103-9e97-f71f78689d27",
   "metadata": {
    "id": "b5723851-9ada-4103-9e97-f71f78689d27"
   },
   "outputs": [],
   "source": [
    "#import the duplicate reports for testing purpose\n",
    "test = pd.read_csv('/content/drive/MyDrive/BugEnricher/duplicates/Firefox_duplicate_reports.csv')\n",
    "# test = test.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a012631-4936-48ed-8531-d04b8450f957",
   "metadata": {
    "id": "5a012631-4936-48ed-8531-d04b8450f957"
   },
   "outputs": [],
   "source": [
    "# preprocessing textually similar and dissimilar duplicates to evaluate\n",
    "def lemmatize2(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess2(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 5:\n",
    "            result.append(lemmatize2(token))\n",
    "    return result\n",
    "\n",
    "#import the duplicate reports for testing purpose\n",
    "test_sim = pd.read_csv('sim.csv')\n",
    "# test_sim = test_sim.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "#import the duplicate reports for testing purpose\n",
    "test_dissim = pd.read_csv('dis.csv')\n",
    "# test_dissim = test_dissim.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "test_sim['Description']= test_sim['Description'].fillna('').astype(str).map(preprocess2)\n",
    "test_dissim['Description']= test_dissim['Description'].fillna('').astype(str).map(preprocess2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e72ea4-2085-4c2c-9d1f-ab8c50a4a723",
   "metadata": {
    "id": "e3e72ea4-2085-4c2c-9d1f-ab8c50a4a723"
   },
   "outputs": [],
   "source": [
    "def lemmatize2(text):\n",
    "    return WordNetLemmatizer().lemmatize(text, pos='v')\n",
    "\n",
    "def preprocess2(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 5:\n",
    "            result.append(lemmatize(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45318315-97da-4b18-9f67-fc1b710270fd",
   "metadata": {
    "id": "45318315-97da-4b18-9f67-fc1b710270fd"
   },
   "outputs": [],
   "source": [
    "test['Description']= test['Description'].fillna('').astype(str).map(preprocess2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c090d694-39a7-4960-b38e-6a77f58701c6",
   "metadata": {
    "id": "c090d694-39a7-4960-b38e-6a77f58701c6"
   },
   "outputs": [],
   "source": [
    "for mod in range(10):\n",
    "    #import all the trained GloVe models\n",
    "    exec('glove{} = Glove.load(\"glove{}.model\")'.format(mod, mod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a6f9e9-b637-460f-b5de-0a65daa50716",
   "metadata": {
    "id": "b3a6f9e9-b637-460f-b5de-0a65daa50716"
   },
   "outputs": [],
   "source": [
    "#This will return the index of cluster in which the master report of duplicate report may reside\n",
    "def sim_with_clusters_lda_topn(DR, n):\n",
    "    vec_bow = dictionary.doc2bow(DR)\n",
    "    x= lda_model[vec_bow]\n",
    "    topic = np.asarray(x)\n",
    "    sim=[]\n",
    "    x= topic[np.argsort(topic[:,1])[-n:][::-1],0]\n",
    "    for i in range(len(x)):\n",
    "        sim.append(int(x[i]))\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971067a2-e298-48e1-b544-ba654f7e96d5",
   "metadata": {
    "id": "971067a2-e298-48e1-b544-ba654f7e96d5"
   },
   "outputs": [],
   "source": [
    "# Convert multiple word embeddings into a single document vector by averaging the word embeddings by GloVe model\n",
    "\n",
    "def average_word_vectors_glove(words, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[model.wv.key_to_index[word]])\n",
    "\n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "    return feature_vector\n",
    "\n",
    "\n",
    "def averaged_word_vectorizer_glove(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.key_to_index)\n",
    "    if(any(isinstance(i, list) for i in corpus)):\n",
    "        features = [average_word_vectors_glove(tokenized_sentence, model, vocabulary, num_features)\n",
    "                      for tokenized_sentence in corpus]\n",
    "        return np.array(features)\n",
    "    else:\n",
    "          features = average_word_vectors_glove(corpus, model, vocabulary, num_features)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4f4ac-8e7b-4f01-a858-523eac18625b",
   "metadata": {
    "id": "69e4f4ac-8e7b-4f01-a858-523eac18625b"
   },
   "outputs": [],
   "source": [
    "# Similarity between two feature vectors using the average of cosine similarity and Euclidean similarity\n",
    "def sim(vec1, vec2):\n",
    "    # Ensure vec1 and vec2 are 2-D arrays for cosine similarity\n",
    "    vec1 = vec1.reshape(1, -1) if len(vec1.shape) == 1 else vec1\n",
    "    vec2 = vec2.reshape(1, -1) if len(vec2.shape) == 1 else vec2\n",
    "\n",
    "    sim1 = 1 / (1 + distance.euclidean(vec1.flatten(), vec2.flatten()))  # Euclidean similarity\n",
    "    sim2 = cosine_similarity(vec1, vec2)[0][0]  # Cosine similarity\n",
    "    sim = (sim1 + sim2) / 2\n",
    "\n",
    "    return sim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba68aa6-0969-404c-8109-573f610e7efa",
   "metadata": {
    "id": "6ba68aa6-0969-404c-8109-573f610e7efa"
   },
   "outputs": [],
   "source": [
    "# Different kinds of fusion of two master report feature vectors and two duplicate report feature vectors\n",
    "def fusion(vec1, vec2, vec3, vec4, fusion_no):\n",
    "\n",
    "    # fusion_no = 1 : concatenation of the vectors\n",
    "    if (fusion_no == '1'):\n",
    "        master = np.concatenate((vec1, vec2), axis=1)\n",
    "        vec_duplicate = np.concatenate((vec3, vec4), axis=0)\n",
    "        vec_duplicate=[vec_duplicate]\n",
    "        return vec_duplicate, master\n",
    "\n",
    "    #fusion_no = 2 : average of the vectors\n",
    "    elif (fusion_no == '2'):\n",
    "        vec3 = [vec3]\n",
    "        vec4 = [vec4]\n",
    "        avg1 = (np.add(vec1, vec2))/2\n",
    "        avg2 = (np.add(vec3, vec4))/2\n",
    "        return avg2, avg1\n",
    "\n",
    "    #fusion_no = 3 : Dimensionality reduction using PCA on concatenation of the vectors\n",
    "    elif (fusion_no == '3'):\n",
    "        master = np.concatenate((vec1, vec2), axis=1)\n",
    "        pca = PCA(n_components=100)\n",
    "        avg_fit = pca.fit(master)\n",
    "        master = pca.transform(master)\n",
    "        vec_duplicate = np.concatenate((vec3, vec4), axis=0)\n",
    "        vec_duplicate=[vec_duplicate]\n",
    "        vec_duplicate = pca.transform(vec_duplicate)\n",
    "        return vec_duplicate, master\n",
    "\n",
    "    #fusion_no = 3 : Dimensionality reduction using PCA on average of the vectors\n",
    "    elif (fusion_no == '4'):\n",
    "        vec3 = [vec3]\n",
    "        vec4 = [vec4]\n",
    "        avg1 = (np.add(vec1, vec2))/2\n",
    "        pca = PCA(n_components=100)\n",
    "        avg_fit = pca.fit(avg1)\n",
    "        master = pca.transform(avg1)\n",
    "        avg2 = (np.add(vec3, vec4))/2\n",
    "        vec_duplicate = pca.transform(avg2)\n",
    "        return vec_duplicate, master\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid value for fusion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179d7b3-6975-4452-9aa1-027ce68b2b52",
   "metadata": {
    "id": "0179d7b3-6975-4452-9aa1-027ce68b2b52"
   },
   "outputs": [],
   "source": [
    "# creation of feature vectors by multimodality feature extraction\n",
    "def feature_vectors_multi_modality(DR, corpus, model1, model2, fusion_no):\n",
    "    master_glove2 = averaged_word_vectorizer_glove(corpus=sent, model=model2, num_features=100)\n",
    "    vec_duplicate2 = averaged_word_vectorizer_glove(corpus=DR, model=model2, num_features=100)\n",
    "    vec_duplicate , master= fusion(master_glove2,vec_duplicate2, fusion_no)\n",
    "    return vec_duplicate,master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa4094-ab58-4c60-bb73-5a8964be027f",
   "metadata": {
    "id": "30fa4094-ab58-4c60-bb73-5a8964be027f"
   },
   "outputs": [],
   "source": [
    "# creation of feature vectors by singlemodality feature extraction\n",
    "def feature_vectors_single_modality(DR, corpus, model1):\n",
    "    master = averaged_word_vectorizer_glove(corpus=sent, model=model1, num_features=100)\n",
    "\n",
    "    vec_duplicate = averaged_word_vectorizer_glove(corpus=DR, model=model1, num_features=100)\n",
    "\n",
    "    vec_duplicate = [vec_duplicate]\n",
    "\n",
    "    return vec_duplicate, master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fb358-c664-4557-ad27-afc9a52cd348",
   "metadata": {
    "id": "c98fb358-c664-4557-ad27-afc9a52cd348"
   },
   "outputs": [],
   "source": [
    "test = test.rename(columns={'Bug ID':'Bug_ID'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10b298-e1ec-44ed-ae0c-324f7a31783e",
   "metadata": {
    "id": "4a10b298-e1ec-44ed-ae0c-324f7a31783e"
   },
   "outputs": [],
   "source": [
    "def compare_topn(model1, cluster, sent, DR, topn, modal):\n",
    "    similarity=[]\n",
    "    if (modal == 'single'):\n",
    "        vec_duplicate, master= feature_vectors_single_modality(DR, sent, model1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid Modality entered')\n",
    "\n",
    "    for doc in range(len(master)):\n",
    "        vec_master = master[doc]\n",
    "        vec_master= [vec_master]\n",
    "        unified_sim = sim(vec_duplicate, vec_master)\n",
    "\n",
    "        similarity.append(unified_sim)\n",
    "    similarity = np.asarray(similarity)\n",
    "    similarity= np.concatenate(similarity, axis=0 )\n",
    "    similarity= np.concatenate(similarity, axis=0 )\n",
    "    max_similar_reports=similarity.argsort()[-topn:][::-1][1:]\n",
    "    return(max_similar_reports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4997ef23-8855-4f22-b5d7-11d9da4f0d94",
   "metadata": {
    "id": "4997ef23-8855-4f22-b5d7-11d9da4f0d94"
   },
   "source": [
    "## LDA and GLOVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd8c42c-5852-4d44-9ba2-78f449b8a451",
   "metadata": {
    "id": "4fd8c42c-5852-4d44-9ba2-78f449b8a451"
   },
   "source": [
    "## on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a83787-2e41-4302-a90f-7c77efff7ff4",
   "metadata": {
    "id": "79a83787-2e41-4302-a90f-7c77efff7ff4"
   },
   "outputs": [],
   "source": [
    "#Returns Top-N master reports\n",
    "dup_id = test.Duplicate_Bug_Ids\n",
    "\n",
    "def compare_topn2(model1, cluster, sent, DR, topn, modal):\n",
    "    similarity = []\n",
    "\n",
    "    if modal == 'single':\n",
    "        vec_duplicate, master = feature_vectors_single_modality2(DR, sent, model1)\n",
    "    else:\n",
    "        raise ValueError('Invalid Modality entered')\n",
    "\n",
    "    for vec_master in master:\n",
    "        unified_sim = sim(vec_duplicate, vec_master)  # Flattening done in sim function\n",
    "        similarity.append(unified_sim)\n",
    "\n",
    "    # Convert similarity list to a numpy array for sorting\n",
    "    similarity = np.array(similarity)\n",
    "    max_similar_reports = similarity.argsort()[-topn:][::-1]\n",
    "\n",
    "    return max_similar_reports\n",
    "\n",
    "\n",
    "def feature_vectors_single_modality2(DR, corpus, model1):\n",
    "    master = averaged_word_vectorizer_glove2(corpus=corpus, model=model1, num_features=100)\n",
    "\n",
    "    vec_duplicate = averaged_word_vectorizer_glove2(corpus=[DR], model=model1, num_features=100)\n",
    "\n",
    "    return vec_duplicate.flatten(), [vec.flatten() for vec in master]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cb1f7b-1726-4cb5-9c96-d40a51599631",
   "metadata": {
    "id": "a5cb1f7b-1726-4cb5-9c96-d40a51599631"
   },
   "outputs": [],
   "source": [
    "def average_word_vectors_glove2(words, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float64\")\n",
    "    nwords = 0.\n",
    "\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            nwords = nwords + 1.\n",
    "            feature_vector = np.add(feature_vector, model.word_vectors[model.dictionary[word]])\n",
    "\n",
    "    if nwords:\n",
    "        feature_vector = np.divide(feature_vector, nwords)\n",
    "\n",
    "    return feature_vector\n",
    "def averaged_word_vectorizer_glove2(corpus, model, num_features):\n",
    "    vocabulary = set(model.dictionary)\n",
    "    if(any(isinstance(i, list) for i in corpus)):\n",
    "        features = [average_word_vectors_glove2(tokenized_sentence, model, vocabulary, num_features)\n",
    "                      for tokenized_sentence in corpus]\n",
    "        return np.array(features)\n",
    "    else:\n",
    "          features = average_word_vectors_glove2(corpus, model, vocabulary, num_features)\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0965db-f5b7-4c8b-b043-401741a54a4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ac0965db-f5b7-4c8b-b043-401741a54a4c",
    "outputId": "ae25b1a4-02ec-449a-81e8-8891f8e5ef8e"
   },
   "outputs": [],
   "source": [
    "#top1\n",
    "vec_acc=[]\n",
    "t1 = time.time()\n",
    "no_of_test_samples= int(200)\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test.Description[i] #The test sample (duplicate report)\n",
    "    n = 1\n",
    "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
    "    v=[]\n",
    "#     print(i)\n",
    "    for max in max_cluster:\n",
    "        exec('cluster = topic_{}'.format(max))              #The predicted cluster\n",
    "#         exec('model1 = ftmodel{}'.format(max))              #The trained FastText model for the predicted cluster   (can be changed to other model as well viz. glove or word2vec)\n",
    "        exec('model1 = glove{}'.format(max))                #The trained Word2Vec model for the predicted cluster   (Doesn't count if using single modality)\n",
    "        exec('sent = topic_{}.Description'.format(max))     #The vocabulary for the predicted cluster\n",
    "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
    "        topn = 1                                          #The number of predicted master report for single predicted cluster\n",
    "        fusion_no = '4'   #Doesn't count if single modality #The selection of fusion used to fuse the word embeddings of two different models  (4 gives the best results)\n",
    "        modal = 'single'                                    #Whether you want to use single feature extraction model or multi model ( for single, it'll consider just model1)\n",
    "         #This will return the Top-N predicted master reports\n",
    "        max_sim = compare_topn2(model1,cluster, sent, sample, topn, modal)\n",
    "        t2 = time.time()\n",
    "\n",
    "        #Comparing the predicted value to the ground truth\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "\n",
    "    if(all(x==v[0] for x in v)):\n",
    "        vec_acc.append(\"0\")\n",
    "    else:\n",
    "        vec_acc.append(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b3813c-87a5-4aa5-945d-635bc36d4968",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f5b3813c-87a5-4aa5-945d-635bc36d4968",
    "outputId": "e3cc445c-4804-49e7-bd72-5d4a58506645"
   },
   "outputs": [],
   "source": [
    "#Evaluating the performance by Recall Rate\n",
    "sum = 0\n",
    "for i,num in enumerate(vec_acc):\n",
    "    sum = sum + int(num)\n",
    "recall_rate = (sum/len(vec_acc))*100\n",
    "print(\"Recall Rate : {} %\".format(recall_rate))\n",
    "print(\"Time : \", (t2-t1)/60, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef630d7d-4280-4b64-9dca-75c20c436b92",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ef630d7d-4280-4b64-9dca-75c20c436b92",
    "outputId": "91e2e70c-2812-42d3-a79e-ab710c52a5e2"
   },
   "outputs": [],
   "source": [
    "#top5\n",
    "vec_acc = []\n",
    "t1 = time.time()\n",
    "no_of_test_samples = min(len(test.Description), 200)\n",
    "\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test.Description[i]\n",
    "    n = 5\n",
    "    max_cluster = sim_with_clusters_lda_topn(sample, n)\n",
    "    v = []\n",
    "\n",
    "    for max in max_cluster:\n",
    "        cluster = eval(f'topic_{max}')\n",
    "        model1 = eval(f'glove{max}')\n",
    "        sent = cluster.Description\n",
    "        cluster = cluster.rename(columns={'Bug ID': 'Bug_ID'})\n",
    "\n",
    "        topn = 5\n",
    "        fusion_no = '4'\n",
    "        modal = 'single'\n",
    "\n",
    "        max_sim = compare_topn2(model1, cluster, sent, sample, topn, modal)\n",
    "\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "    vec_acc.append(\"0\" if all(x == v[0] for x in v) else \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6288d6-60e4-461f-b8ff-1b9798bd0a00",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fb6288d6-60e4-461f-b8ff-1b9798bd0a00",
    "outputId": "fa8e7964-bd3e-458c-a4c3-a6c6c090c080"
   },
   "outputs": [],
   "source": [
    "# Evaluating the performance by Recall Rate\n",
    "total_sum = 0\n",
    "for num in vec_acc:\n",
    "    total_sum += int(num)\n",
    "\n",
    "recall_rate = (total_sum / len(vec_acc)) * 100 if len(vec_acc) > 0 else 0\n",
    "\n",
    "print(\"Recall Rate: {:.2f} %\".format(recall_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11a440d-989b-451c-ba59-e51b87f8dfdd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d11a440d-989b-451c-ba59-e51b87f8dfdd",
    "outputId": "c50e25e6-08aa-4b65-f5f0-1dd7db9ab002"
   },
   "outputs": [],
   "source": [
    "#top10\n",
    "vec_acc = []\n",
    "t1 = time.time()\n",
    "no_of_test_samples = min(len(test.Description), 200)\n",
    "\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test.Description[i]\n",
    "    n = 10\n",
    "    max_cluster = sim_with_clusters_lda_topn(sample, n)\n",
    "    v = []\n",
    "\n",
    "    for max in max_cluster:\n",
    "        cluster = eval(f'topic_{max}')\n",
    "        model1 = eval(f'glove{max}')\n",
    "        sent = cluster.Description\n",
    "        cluster = cluster.rename(columns={'Bug ID': 'Bug_ID'})\n",
    "\n",
    "        topn = 10\n",
    "        fusion_no = '4'\n",
    "        modal = 'single'\n",
    "\n",
    "        max_sim = compare_topn2(model1, cluster, sent, sample, topn, modal)\n",
    "\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "    vec_acc.append(\"0\" if all(x == v[0] for x in v) else \"1\")\n",
    "\n",
    "# Evaluating the performance by Recall Rate\n",
    "total_sum = 0\n",
    "for num in vec_acc:\n",
    "    total_sum += int(num)\n",
    "\n",
    "recall_rate = (total_sum / len(vec_acc)) * 100 if len(vec_acc) > 0 else 0\n",
    "\n",
    "print(\"Recall Rate: {:.2f} %\".format(recall_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dd8f99-dbe7-4535-a46e-370c623d5b75",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66dd8f99-dbe7-4535-a46e-370c623d5b75",
    "outputId": "1b3d340e-5a3d-4d05-8aa4-8b991eaad96b"
   },
   "outputs": [],
   "source": [
    "#top100\n",
    "vec_acc = []\n",
    "t1 = time.time()\n",
    "no_of_test_samples = min(len(test.Description), 200)\n",
    "\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test.Description[i]\n",
    "    n = 100\n",
    "    max_cluster = sim_with_clusters_lda_topn(sample, n)\n",
    "    v = []\n",
    "\n",
    "    for max in max_cluster:\n",
    "        cluster = eval(f'topic_{max}')\n",
    "        model1 = eval(f'glove{max}')\n",
    "        sent = cluster.Description\n",
    "        cluster = cluster.rename(columns={'Bug ID': 'Bug_ID'})\n",
    "\n",
    "        topn = 100\n",
    "        fusion_no = '4'\n",
    "        modal = 'single'\n",
    "\n",
    "        max_sim = compare_topn2(model1, cluster, sent, sample, topn, modal)\n",
    "\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "    vec_acc.append(\"0\" if all(x == v[0] for x in v) else \"1\")\n",
    "\n",
    "# Evaluating the performance by Recall Rate\n",
    "total_sum = 0\n",
    "for num in vec_acc:\n",
    "    total_sum += int(num)\n",
    "\n",
    "recall_rate = (total_sum / len(vec_acc)) * 100 if len(vec_acc) > 0 else 0\n",
    "\n",
    "print(\"Recall Rate: {:.2f} %\".format(recall_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c7e28-9b75-48b7-93f1-0e79556d62d7",
   "metadata": {
    "id": "f84c7e28-9b75-48b7-93f1-0e79556d62d7"
   },
   "source": [
    "# On Textually Similar and Dissimilar datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0eee0-4394-4109-aaeb-ceb5f71494c7",
   "metadata": {
    "id": "2af0eee0-4394-4109-aaeb-ceb5f71494c7"
   },
   "outputs": [],
   "source": [
    "nan_value = float(\"NaN\")\n",
    "test_sim.replace(\"\", nan_value, inplace=True)\n",
    "test_sim.dropna(subset = [\"Duplicate_Bug_Ids\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db66d6b3-ddf5-4079-b2c8-a8d6a5cd0773",
   "metadata": {
    "id": "db66d6b3-ddf5-4079-b2c8-a8d6a5cd0773"
   },
   "outputs": [],
   "source": [
    "nan_value = float(\"NaN\")\n",
    "test_dissim.replace(\"\", nan_value, inplace=True)\n",
    "test_dissim.dropna(subset = [\"Duplicate_Bug_Ids\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b156ca5e-b41c-42bd-ac1b-abf5aa46ef2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b156ca5e-b41c-42bd-ac1b-abf5aa46ef2c",
    "outputId": "a4182887-9099-42db-a84d-d54568ee3823"
   },
   "outputs": [],
   "source": [
    "cond = (test_sim['Duplicate_Bug_Ids'] == 'NaN')\n",
    "cond.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525588a3-2eac-422b-b7a3-8b4a493a9342",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "525588a3-2eac-422b-b7a3-8b4a493a9342",
    "outputId": "8aa580a9-8d4a-4d05-ba2a-143720adf782"
   },
   "outputs": [],
   "source": [
    "cond = (test_dissim['Duplicate_Bug_Ids'] == 'NaN')\n",
    "cond.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c0f56-4e0c-40c1-ab97-5c1930ba6e03",
   "metadata": {
    "id": "4e6c0f56-4e0c-40c1-ab97-5c1930ba6e03"
   },
   "outputs": [],
   "source": [
    "test_sim = test_sim.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c04640-616f-48b2-bd3a-04b9d0763613",
   "metadata": {
    "id": "c0c04640-616f-48b2-bd3a-04b9d0763613"
   },
   "outputs": [],
   "source": [
    "test_dissim = test_dissim.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284119ae-5322-45a9-992e-e2d1da6ecc6d",
   "metadata": {
    "id": "284119ae-5322-45a9-992e-e2d1da6ecc6d"
   },
   "source": [
    "# Textually Similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a441a06-070a-4d30-a48f-bea08549acfe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a441a06-070a-4d30-a48f-bea08549acfe",
    "outputId": "fccee6e6-f842-4197-da0d-352ced9a61e9"
   },
   "outputs": [],
   "source": [
    "#top 1\n",
    "vec_acc = []\n",
    "t1 = time.time()\n",
    "no_of_test_samples = min(len(test_sim.Description), 200)\n",
    "\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test_sim.Description[i]\n",
    "    n = 1\n",
    "    max_cluster = sim_with_clusters_lda_topn(sample, n)\n",
    "    v = []\n",
    "\n",
    "    for max in max_cluster:\n",
    "        cluster = eval(f'topic_{max}')\n",
    "        model1 = eval(f'glove{max}')\n",
    "        sent = cluster.Description\n",
    "        cluster = cluster.rename(columns={'Bug ID': 'Bug_ID'})\n",
    "\n",
    "        topn = 1\n",
    "        fusion_no = '4'\n",
    "        modal = 'single'\n",
    "\n",
    "        max_sim = compare_topn2(model1, cluster, sent, sample, topn, modal)\n",
    "\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test_sim.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "    vec_acc.append(\"0\" if all(x == v[0] for x in v) else \"1\")\n",
    "\n",
    "\n",
    "# Evaluating the performance by Recall Rate\n",
    "total_sum = 0\n",
    "for num in vec_acc:\n",
    "    total_sum += int(num)\n",
    "\n",
    "recall_rate = (total_sum / len(vec_acc)) * 100 if len(vec_acc) > 0 else 0\n",
    "\n",
    "print(\"Recall Rate: {:.2f} %\".format(recall_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6df36d-69c0-4ec9-813b-2903523803bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a6df36d-69c0-4ec9-813b-2903523803bb",
    "outputId": "5a8fbc53-e05d-4b4b-d5e5-1bd2833a7ac1"
   },
   "outputs": [],
   "source": [
    "#top 5\n",
    "vec_acc = []\n",
    "t1 = time.time()\n",
    "no_of_test_samples = min(len(test_sim.Description), 200)\n",
    "\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test_sim.Description[i]\n",
    "    n = 5\n",
    "    max_cluster = sim_with_clusters_lda_topn(sample, n)\n",
    "    v = []\n",
    "\n",
    "    for max in max_cluster:\n",
    "        cluster = eval(f'topic_{max}')\n",
    "        model1 = eval(f'glove{max}')\n",
    "        sent = cluster.Description\n",
    "        cluster = cluster.rename(columns={'Bug ID': 'Bug_ID'})\n",
    "\n",
    "        topn = 5\n",
    "        fusion_no = '4'\n",
    "        modal = 'single'\n",
    "\n",
    "        max_sim = compare_topn2(model1, cluster, sent, sample, topn, modal)\n",
    "\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test_sim.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "    vec_acc.append(\"0\" if all(x == v[0] for x in v) else \"1\")\n",
    "\n",
    "\n",
    "# Evaluating the performance by Recall Rate\n",
    "total_sum = 0\n",
    "for num in vec_acc:\n",
    "    total_sum += int(num)\n",
    "\n",
    "recall_rate = (total_sum / len(vec_acc)) * 100 if len(vec_acc) > 0 else 0\n",
    "\n",
    "print(\"Recall Rate: {:.2f} %\".format(recall_rate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd202a-9eea-407f-8baa-f753a2cae4f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9fd202a-9eea-407f-8baa-f753a2cae4f4",
    "outputId": "9a4c67e2-c9ff-4dec-bb2b-85cea89be8b4"
   },
   "outputs": [],
   "source": [
    "#top 10\n",
    "vec_acc=[]\n",
    "t1 = time.time()\n",
    "no_of_test_samples= int(200)\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test.Description[i] #The test sample (duplicate report)\n",
    "    n = 10\n",
    "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
    "    v=[]\n",
    "#     print(i)\n",
    "    for max in max_cluster:\n",
    "        exec('cluster = topic_{}'.format(max))              #The predicted cluster\n",
    "#         exec('model1 = ftmodel{}'.format(max))              #The trained FastText model for the predicted cluster   (can be changed to other model as well viz. glove or word2vec)\n",
    "        exec('model1 = glove{}'.format(max))                #The trained Word2Vec model for the predicted cluster   (Doesn't count if using single modality)\n",
    "        exec('sent = topic_{}.Description'.format(max))     #The vocabulary for the predicted cluster\n",
    "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
    "        topn = 10                                          #The number of predicted master report for single predicted cluster\n",
    "        fusion_no = '4'   #Doesn't count if single modality #The selection of fusion used to fuse the word embeddings of two different models  (4 gives the best results)\n",
    "        modal = 'single'                                    #Whether you want to use single feature extraction model or multi model ( for single, it'll consider just model1)\n",
    "         #This will return the Top-N predicted master reports\n",
    "        max_sim = compare_topn2(model1,cluster, sent, sample, topn, modal)\n",
    "        t2 = time.time()\n",
    "\n",
    "        #Comparing the predicted value to the ground truth\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "\n",
    "    if(all(x==v[0] for x in v)):\n",
    "        vec_acc.append(\"0\")\n",
    "    else:\n",
    "        vec_acc.append(\"1\")\n",
    "\n",
    "\n",
    "# Evaluating the performance by Recall Rate\n",
    "sum = 0\n",
    "for i,num in enumerate(vec_acc):\n",
    "    sum = sum + int(num)\n",
    "recall_rate = (sum/len(vec_acc))*100\n",
    "print(\"Recall Rate : {} %\".format(recall_rate))\n",
    "print(\"Time : \", (t2-t1)/60, \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f427591e-eeb0-49a5-8976-06f49b880f30",
   "metadata": {
    "id": "f427591e-eeb0-49a5-8976-06f49b880f30"
   },
   "outputs": [],
   "source": [
    "#top 100\n",
    "vec_acc = []\n",
    "t1 = time.time()\n",
    "no_of_test_samples = min(len(test_sim.Description), 200)\n",
    "\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test_sim.Description[i]\n",
    "    n = 100\n",
    "    max_cluster = sim_with_clusters_lda_topn(sample, n)\n",
    "    v = []\n",
    "\n",
    "    for max in max_cluster:\n",
    "        cluster = eval(f'topic_{max}')\n",
    "        model1 = eval(f'glove{max}')\n",
    "        sent = cluster.Description\n",
    "        cluster = cluster.rename(columns={'Bug ID': 'Bug_ID'})\n",
    "\n",
    "        topn = 100\n",
    "        fusion_no = '4'\n",
    "        modal = 'single'\n",
    "\n",
    "        max_sim = compare_topn2(model1, cluster, sent, sample, topn, modal)\n",
    "\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test_sim.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "    vec_acc.append(\"0\" if all(x == v[0] for x in v) else \"1\")\n",
    "\n",
    "\n",
    "# Evaluating the performance by Recall Rate\n",
    "total_sum = 0\n",
    "for num in vec_acc:\n",
    "    total_sum += int(num)\n",
    "\n",
    "recall_rate = (total_sum / len(vec_acc)) * 100 if len(vec_acc) > 0 else 0\n",
    "\n",
    "print(\"Recall Rate: {:.2f} %\".format(recall_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b93308-baf0-470e-8adf-b555b1a8bf54",
   "metadata": {
    "id": "c4b93308-baf0-470e-8adf-b555b1a8bf54",
    "tags": []
   },
   "source": [
    "# Textually dissimilar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ac4d5-1ce5-4c82-966c-e980060e9efe",
   "metadata": {
    "id": "500ac4d5-1ce5-4c82-966c-e980060e9efe"
   },
   "outputs": [],
   "source": [
    "#top 1\n",
    "vec_acc = []\n",
    "t1 = time.time()\n",
    "no_of_test_samples = min(len(test_dissim.Description), 200)\n",
    "\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test_dissim.Description[i]\n",
    "    n = 1\n",
    "    max_cluster = sim_with_clusters_lda_topn(sample, n)\n",
    "    v = []\n",
    "\n",
    "    for max in max_cluster:\n",
    "        cluster = eval(f'topic_{max}')\n",
    "        model1 = eval(f'glove{max}')\n",
    "        sent = cluster.Description\n",
    "        cluster = cluster.rename(columns={'Bug ID': 'Bug_ID'})\n",
    "\n",
    "        topn = 1\n",
    "        fusion_no = '4'\n",
    "        modal = 'single'\n",
    "\n",
    "        max_sim = compare_topn2(model1, cluster, sent, sample, topn, modal)\n",
    "\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test_dissim.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "    vec_acc.append(\"0\" if all(x == v[0] for x in v) else \"1\")\n",
    "\n",
    "\n",
    "# Evaluating the performance by Recall Rate\n",
    "total_sum = 0\n",
    "for num in vec_acc:\n",
    "    total_sum += int(num)\n",
    "\n",
    "recall_rate = (total_sum / len(vec_acc)) * 100 if len(vec_acc) > 0 else 0\n",
    "\n",
    "print(\"Recall Rate: {:.2f} %\".format(recall_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647901f4-4ea9-4c51-91f1-d2521007b2f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "647901f4-4ea9-4c51-91f1-d2521007b2f6",
    "outputId": "3176737a-07b2-4ded-ee34-34c9768b6341"
   },
   "outputs": [],
   "source": [
    "#top 5\n",
    "vec_acc=[]\n",
    "t1 = time.time()\n",
    "no_of_test_samples= int(200)\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test_dissim.Description[i] #The test sample (duplicate report)\n",
    "    n = 5\n",
    "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
    "    v=[]\n",
    "#     print(i)\n",
    "    for max in max_cluster:\n",
    "        exec('cluster = topic_{}'.format(max))              #The predicted cluster\n",
    "#         exec('model1 = ftmodel{}'.format(max))              #The trained FastText model for the predicted cluster   (can be changed to other model as well viz. glove or word2vec)\n",
    "        exec('model1 = glove{}'.format(max))                #The trained Word2Vec model for the predicted cluster   (Doesn't count if using single modality)\n",
    "        exec('sent = topic_{}.Description'.format(max))     #The vocabulary for the predicted cluster\n",
    "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
    "\n",
    "        topn = 5                                          #The number of predicted master report for single predicted cluster\n",
    "        fusion_no = '4'   #Doesn't count if single modality #The selection of fusion used to fuse the word embeddings of two different models  (4 gives the best results)\n",
    "        modal = 'single'                                    #Whether you want to use single feature extraction model or multi model ( for single, it'll consider just model1)\n",
    "         #This will return the Top-N predicted master reports\n",
    "        max_sim = compare_topn2(model1,cluster, sent, sample, topn, modal)\n",
    "        t2 = time.time()\n",
    "\n",
    "        #Comparing the predicted value to the ground truth\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test_dissim.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "\n",
    "    if(all(x==v[0] for x in v)):\n",
    "        vec_acc.append(\"0\")\n",
    "    else:\n",
    "        vec_acc.append(\"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be952385-bd6a-46eb-8ba4-15927683d035",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be952385-bd6a-46eb-8ba4-15927683d035",
    "outputId": "10e837c7-e6c4-4d15-ef5c-905a78158734"
   },
   "outputs": [],
   "source": [
    "#top 10\n",
    "vec_acc = []\n",
    "t1 = time.time()\n",
    "no_of_test_samples = min(len(test_sim.Description), 200)\n",
    "\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test_sim.Description[i]\n",
    "    n = 10\n",
    "    max_cluster = sim_with_clusters_lda_topn(sample, n)\n",
    "    v = []\n",
    "\n",
    "    for max in max_cluster:\n",
    "        cluster = eval(f'topic_{max}')\n",
    "        model1 = eval(f'glove{max}')\n",
    "        sent = cluster.Description\n",
    "        cluster = cluster.rename(columns={'Bug ID': 'Bug_ID'})\n",
    "\n",
    "        topn = 10\n",
    "        fusion_no = '4'\n",
    "        modal = 'single'\n",
    "\n",
    "        max_sim = compare_topn2(model1, cluster, sent, sample, topn, modal)\n",
    "\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test_sim.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "    vec_acc.append(\"0\" if all(x == v[0] for x in v) else \"1\")\n",
    "\n",
    "\n",
    "# Evaluating the performance by Recall Rate\n",
    "total_sum = 0\n",
    "for num in vec_acc:\n",
    "    total_sum += int(num)\n",
    "\n",
    "recall_rate = (total_sum / len(vec_acc)) * 100 if len(vec_acc) > 0 else 0\n",
    "\n",
    "print(\"Recall Rate: {:.2f} %\".format(recall_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2f1bc1-4545-442d-b4ac-69bfe1a961b1",
   "metadata": {
    "id": "ba2f1bc1-4545-442d-b4ac-69bfe1a961b1"
   },
   "outputs": [],
   "source": [
    "#top 100\n",
    "vec_acc=[]\n",
    "t1 = time.time()\n",
    "no_of_test_samples= int(200)\n",
    "for i in range(no_of_test_samples):\n",
    "    print(f'\\rRunning sample {i}', end='')\n",
    "    sample = test_dissim.Description[i] #The test sample (duplicate report)\n",
    "    n = 100\n",
    "    max_cluster =sim_with_clusters_lda_topn(sample, n)\n",
    "    v=[]\n",
    "#     print(i)\n",
    "    for max in max_cluster:\n",
    "        exec('cluster = topic_{}'.format(max))              #The predicted cluster\n",
    "#         exec('model1 = ftmodel{}'.format(max))              #The trained FastText model for the predicted cluster   (can be changed to other model as well viz. glove or word2vec)\n",
    "        exec('model1 = glove{}'.format(max))                #The trained Word2Vec model for the predicted cluster   (Doesn't count if using single modality)\n",
    "        exec('sent = topic_{}.Description'.format(max))     #The vocabulary for the predicted cluster\n",
    "        cluster = cluster.rename(columns={'Bug ID':'Bug_ID'})\n",
    "\n",
    "        topn = 100\n",
    "        fusion_no = '4'   #Doesn't count if single modality #The selection of fusion used to fuse the word embeddings of two different models  (4 gives the best results)\n",
    "        modal = 'single'\n",
    "        max_sim = compare_topn2(model1,cluster, sent, sample, topn, modal)\n",
    "        t2 = time.time()\n",
    "\n",
    "        #Comparing the predicted value to the ground truth\n",
    "        for num in max_sim:\n",
    "            if (cluster.Bug_ID[num] == test_dissim.Duplicate_Bug_Ids[i]):\n",
    "                v.append(\"1\")\n",
    "            else:\n",
    "                v.append(\"0\")\n",
    "\n",
    "    if(all(x==v[0] for x in v)):\n",
    "        vec_acc.append(\"0\")\n",
    "    else:\n",
    "        vec_acc.append(\"1\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
